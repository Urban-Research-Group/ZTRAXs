{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode bytes in position 15-16: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\NPOLIM~1\\AppData\\Local\\Temp\\38/ipykernel_23580/2153246375.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfolders\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[0mfiles_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m     \u001b[0mfiles_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_headers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;31m# Combine files_df (merge files on key)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\NPOLIM~1\\AppData\\Local\\Temp\\38/ipykernel_23580/2153246375.py\u001b[0m in \u001b[0;36madd_headers\u001b[1;34m(files_df, folder)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;31m# Determines which separate excel layout file to use. Layout files contain a list of headers for each file within the folder.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"ZAsmt\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mlayout_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'asmt_layout.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mlayout_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'trans_layout.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_dtype_objs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode bytes in position 15-16: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "folders = [\"ZAsmt\", \"ZTrans\"]\n",
    "\n",
    "\n",
    "ZAsmt = [\"Main\", \"AdditionalPropertyAddress\", \"BKManagedSpecific\", \"Building\", \"BuildingAreas\",\n",
    "         \"MailAddress\", \"Name\", \"SaleData\", \"TaxDistrict\", \"TaxExemption\", \"TypeConstruction\", \"Value\"]\n",
    "ZTrans = [\"Main\", \"BKManagedSpecific\", \"BuyerMailAddress\", \"BuyerName\",\n",
    "          \"ForeclosureNameAddress\", \"SellerMailAddress\", \"SellerName\", \"SellerNameDescriptionCode\"]\n",
    "\n",
    "file_layout = {\"ZAsmt\": ZAsmt, \"ZTrans\": ZTrans}\n",
    "\n",
    "vars_interest = {\"Main\": [\"RowID\", \"TransId\", \"BatchID\", \"ImportParcelID\", \"AssessorParcelNumber\", \"State\", \"County\", \"PropertyCity\", \"PropertyZip\", \"PropertyZip4\", \"PropertyAddressCensusTrackAndBlock\",\n",
    "                          \"OriginalPropertyFullStreetAddress\", \"PropertyAddressLatitude\", \"PropertyAddressLongitude\", \"PropertyZoningSourceCode\", \"TaxIDNumber\", \"TaxAmount\", \"TaxYear\", \"TaxDelinquencyFlag\",\n",
    "                          \"TaxDelinquencyAmount\", \"TaxDelinquencyYear\", \"LotSizeSquareFeet\", \"ValueCertDate\", \"DocumentDate\", \"DocumentTypeStndCode\", \"LoanAmount\", \"LoanAmountStndCode\", \"MaximumLoanAmount\",\n",
    "                          \"LoanTypeClosedOpenEndStndCode\", \"LoanTypeFutureAdvancedFlag\", \"LoanTypeProgramStndCode\", \"LoanRateTypeStndCode\", \"LoanDueDate\", \"LoanTermMonths\", \"LoanTermYears\"],\n",
    "                 \"Building\": [\"RowID\", \"TransId\", \"PropertyCountyLandUseCode\", \"YearBuilt\", \"ArchitecturalStyleStndCode\", \"Number of bedroom\", \"Number of Bathroom\", \"Number of stories\", \"Number of Rooms\", \"Number of units NoOfUnits\"],\n",
    "                 \"BuildingArea\": [\"RowID\", \"TransId\", \"BuildingAreaSqft\"],\n",
    "                 \"SaleData\": [\"RowID\", \"TransId\", \"SalePriceAmount, BuyerFullName\", \"DocumentDate\"],\n",
    "                 \"Value\": [\"RowID\", \"TransId\", \"LandAssessedValue\", \"ImprovementAssessedValue\", \"TotalAssessedValue\", \"AssessmentYear\", \"TotalMarketValue\", \"LandAppraisalData\", \"TotalAppraisalValue\", \"AppraisalValueYear\", \"SalesPriceAmount\"],\n",
    "                 \"BuyerName\": [\"RowID\", \"TransId\", \"BuyerIndividualFullName\",\"BuyerNonIndividualName\"],\n",
    "                 \"BuyerMailAddress\": [\"RowID\", \"TransId\", \"BuyerMailFullStreetAddress\", \"BuyerMailCity\", \"BuyerMailState\", \"BuyerMailZip\", \"BuyerMailZip4\", \"BuyerMailAddressCensusTrackAndBlock\"],\n",
    "                 \"SellerMailAddress\": [\"RowID\", \"TransId\", \"SellerIndividualFullName\", \"SellerNonIndividualName\", \"SellerMailFullStreetAddress\", \"SellerMailCity\", \"SellerMailState\", \"SellerMailZip\", \"SellerMailZip4\", \"SellerMailAddressLatitude\", \"SellerMailAddressLongitude\", \"SellerMailAddressCensusTrackAndBlock\"], \n",
    "                 \"BKManagedSpecific\": [\"RowID\", \"TransId\", \"DeedTransType\"], \n",
    "                 \"ForeClosureNameAddress\": [\"RowID\", \"TransID\", \"FCMailIndividualFullName\",\"FCMailNonIndividualName\", \"FCMailFullStreetAddress\", \"FCMailCity\", \"FCMailState\", \"FCMailZip\", \"FCMailZip4\"]}\n",
    "\n",
    "\n",
    "def insert_headers(folder, file, columns):\n",
    "    # Removes the 'ut' at the beginning of the file name, which was the format given in the layout file\n",
    "    curr_file = file[2:]\n",
    "    print(curr_file)\n",
    "\n",
    "    if curr_file not in vars_interest.keys():\n",
    "        print(curr_file, \" is not of interest (file)\")\n",
    "        return dd.DataFrame\n",
    "\n",
    "    # Creates a DF of the current file\n",
    "    try:\n",
    "        file_df = dd.read_csv('' + folder + '\\\\' + curr_file + '.txt', sep='|', on_bad_lines='skip',\n",
    "                              low_memory=False, encoding='latin-1', index_col=False, header=None)\n",
    "        print(curr_file, \" opened successfully.\")\n",
    "    except Exception as e:\n",
    "        print(curr_file, \" cannot be accessed. Skipping...\")\n",
    "        print(e)\n",
    "        print(\"\")\n",
    "        return dd.DataFrame\n",
    "\n",
    "    # Adds column names to the DF\n",
    "    for i,column in enumerate(columns):\n",
    "        columns[i] = column.lower()\n",
    "\n",
    "    file_df.columns = columns\n",
    "    print(columns, \" : Added (lowercase) column names\")\n",
    "\n",
    "    for column in columns:\n",
    "        curr_vars_interest = vars_interest[curr_file]\n",
    "        for i,var in enumerate(curr_vars_interest):\n",
    "            curr_vars_interest[i] = var.lower()\n",
    "\n",
    "        if column.lower() not in curr_vars_interest:\n",
    "            print(column, \" is not of interest. Dropping...\")\n",
    "            file_df.drop(column, axis=\"columns\", inplace=True)\n",
    "\n",
    "    print(\"\")\n",
    "    return file_df\n",
    "\n",
    "\n",
    "def add_headers(files_df, folder):\n",
    "    # Determines which separate excel layout file to use. Layout files contain a list of headers for each file within the folder.\n",
    "    if folder == \"ZAsmt\":\n",
    "        layout_file = pd.read_csv('asmt_layout.xlsx')\n",
    "    else:\n",
    "        layout_file = pd.read_csv('trans_layout.xlsx')\n",
    "\n",
    "    # List of file names in given folder; file names are repeated once in the resultant list for each variable they have.\n",
    "    # Data is taken from the layout file.\n",
    "    # Example: if BuyerName has 6 variables, it will be repeated in file_names 6 times. This will make a later operation easier.\n",
    "    file_names = (layout_file[\"TableName\"].to_numpy()).tolist()\n",
    "\n",
    "    # List of column names taken from the \"FieldName\" column of the layout file.\n",
    "    column_headers = (layout_file[\"FieldName\"].to_numpy()).tolist()\n",
    "\n",
    "    # Initialized a dictionary with each file name being a key\n",
    "    file_col_headers = dict.fromkeys(file_names)\n",
    "\n",
    "    for key in file_col_headers:\n",
    "        file_col_headers[key] = []\n",
    "\n",
    "    # Determines the file's associated column and places it in a list on the associated dict key\n",
    "    total_var_count = 0\n",
    "    for file in file_names:\n",
    "        file_col_headers[file].append(column_headers[total_var_count])\n",
    "        total_var_count += 1\n",
    "\n",
    "    # file_col_headers now contains a complete dict with key 'ut' + Filename (how the layout file formats the name)\n",
    "    # and values equal to a list of column names.\n",
    "\n",
    "    # log\n",
    "    print(folder, total_var_count,\n",
    "          \": This number should be equal to the number of rows in the layout file (for the given folder) minus 1\")\n",
    "    print(\"\")\n",
    "\n",
    "    #\n",
    "    for file in file_col_headers.keys():\n",
    "        curr_df = insert_headers(folder, file, file_col_headers[file])\n",
    "        if not curr_df.empty:\n",
    "            files_df.append(curr_df)\n",
    "    return files_df\n",
    "\n",
    "\n",
    "# ----------------\n",
    "# MAIN\n",
    "# ----------------\n",
    "folder = \"ZAsmt\"\n",
    "\n",
    "# for folder in folders:\n",
    "# DF containing all working data files, will be combined at ends\n",
    "asmt_df = dd.DataFrame\n",
    "trans_df = dd.DataFrame\n",
    "\n",
    "for folder in folders:\n",
    "    files_df = []\n",
    "    files_df = add_headers(files_df, folder)\n",
    "\n",
    "    # Combine files_df (merge files on key)\n",
    "    # -----------------\n",
    "    final_df = files_df[0]\n",
    "    index = 0\n",
    "\n",
    "    for file in files_df:\n",
    "        if index > 0:\n",
    "            if folder == \"ZAsmt\":\n",
    "                final_df = final_df.merge(file, on=\"rowid\", how=\"outer\")\n",
    "            else:\n",
    "                print(files_df)\n",
    "                for file in files_df:\n",
    "                    print (file.head)\n",
    "                final_df = final_df.merge(file, on=\"transid\", how=\"outer\")\n",
    "        index = index + 1\n",
    "\n",
    "    if folder == \"ZAsmt\":\n",
    "        asmt_df = final_df\n",
    "    else:\n",
    "        trans_df = final_df\n",
    "\n",
    "final_df = asmt_df.merge(trans_df, on=\"batchid\", how=\"outer\").dropna()\n",
    "\n",
    "print(\"Writing to file...\")\n",
    "final_df.to_csv(\"out.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
